# Doc2Train v2.0 Enhanced - Unified Configuration
# Edit this file to customize all aspects of document processing

# Basic Settings
mode: "extract-only"  # extract-only, generate, full, resume, analyze, direct_to_llm
input_path: "input"  # Will be set by command line if not provided
output_dir: "output"
output_format: ["jsonl", "json"] # jsonl, json, csv, txt

# Processing Settings
processing:
  use_async: true  # Use async LLM calls for faster processing
  threads: 4
  max_workers: 4
  batch_size: 10
  timeout: 300  # seconds
  max_file_size: "100MB"
  use_cache: true
  save_per_file: false  # Save each file immediately after processing
  # NEW: Auto-stop features
  auto_stop_on_quota_exceeded: false  # Stop when API quota is hit
  auto_stop_on_consecutive_failures: 3  # Stop after N consecutive failures
  auto_stop_after_time: null  # Stop after X minutes (null = no limit)
  auto_stop_after_files: null  # Stop after N files (null = no limit)

# Page Control (for PDFs)
pages:
  start_page: 1
  end_page: null  # null means last page
  skip_pages: []  # List of page numbers to skip, e.g., [1, 2, 5]

# Quality Control
quality:
  min_image_size: 1000  # pixels
  min_text_length: 100  # characters
  skip_single_color_images: false
  header_regex: ""  # Regex to remove headers/footers
  quality_threshold: 0.7  # 0.0 to 1.0

# Features
features:
  extract_images: true
  use_ocr: true
  include_vision: false  # Process images with vision LLMs
  smart_pdf_analysis: true  # Use smart PDF analysis

# LLM Settings
llm:
  discover_plugins: true
  provider_capabilities: true
  list_providers: true
  list_plugins: true
  provider: "openai"  # openai, deepseek, local
  model: ""  # Leave empty for auto-selection
  fallback_provider: "deepseek"
  max_concurrent_calls: 5  # For async processing
  llm_providers:
    anthropic:
      api_key: "sk-ant-xxxx"
      base_url: "https://api.anthropic.com/v1"
      default_model: "claude-3-5-sonnet-20241022"
      timeout: 30
      temperature: 0.7
    openai:
      api_key: "sk-oa-xxxx"
      base_url: "https://api.openai.com/v1"
      default_model: "gpt-4o"
      temperature: 0.5
      max_tokens: 4096
    deepseek:
      api_key: "sk-ds-xxxx"
      base_url: "https://api.deepseek.com/v1"
      default_model: "deepseek-chat"
      temperature: 0.4


  # API Keys (can also be set via environment variables)
  api_keys:
    openai: ""  # Set OPENAI_API_KEY in .env instead
    deepseek: ""  # Set DEEPSEEK_API_KEY in .env instead

# Generation Settings
generation:
  types: ["conversations", "qa_pairs"]  # conversations, embeddings, qa_pairs, summaries
  chunk_size: 4000
  overlap: 200

# Custom Prompts (override defaults)
prompts:
  style: "default"  # default, detailed, concise, academic, casual, creative, professional

  # Custom prompt templates (optional - will use style defaults if not specified)
  custom:
    conversations: |
      Based on this content, create a natural multi-turn conversation between a user and an AI assistant.
      Make it educational and engaging. Include 3-4 exchanges (user question -> AI response).

      Content:
      {chunk}

      Format your response as JSON:
      {{"conversations": [
          {{"messages": [
              {{"role": "user", "content": "user question"}},
              {{"role": "assistant", "content": "AI response"}}
          ]}},
          {{"messages": [
              {{"role": "user", "content": "follow-up question"}},
              {{"role": "assistant", "content": "AI response"}}
          ]}}
      ]}}

    qa_pairs: |
      Create specific questions that can be answered from this content.
      Make sure answers are complete and accurate.

      Content:
      {chunk}

      Format as JSON:
      {{"qa_pairs": [
          {{"question": "What is...", "answer": "Complete answer based on content"}},
          {{"question": "How does...", "answer": "Detailed explanation"}}
      ]}}

    summaries: |
      Create a concise summary of this content, highlighting the key points.

      Content:
      {chunk}

      Format as JSON:
      {{"summary": "Your concise summary here"}}

    embeddings: |
      From this content, create pairs of sentences that have similar meanings but different wording.
      Also create some pairs with different meanings for contrast.

      Content:
      {chunk}

      Format as JSON:
      {{"pairs": [
          {{"sentence1": "first sentence", "sentence2": "similar meaning sentence", "similarity": 0.9}},
          {{"sentence1": "different sentence", "sentence2": "unrelated sentence", "similarity": 0.1}}
      ]}}

# Debug Settings
debug:
  verbose: false
  show_progress: true
  show_images: false
  test_mode: false
  dry_run: false
  benchmark: false
  validate_only: false

# Advanced Settings
advanced:
  llm_plugin_dir: ""
  resume_from: ""
  clear_cache_after: true

  # Prompt style definitions
  prompt_styles:
    detailed:
      conversations: "Create comprehensive, detailed conversations with thorough explanations and multiple follow-up questions."
      qa_pairs: "Generate detailed questions with comprehensive, well-explained answers."
      summaries: "Create detailed summaries that cover all important aspects thoroughly."

    concise:
      conversations: "Create brief, focused conversations that get straight to the point."
      qa_pairs: "Generate clear, direct questions with concise but complete answers."
      summaries: "Create brief summaries focusing only on the most essential points."

    academic:
      conversations: "Create scholarly conversations with proper citations and academic discourse."
      qa_pairs: "Generate academic-style questions with evidence-based, well-researched answers."
      summaries: "Create academic summaries with proper structure and formal language."

    casual:
      conversations: "Create friendly, casual conversations using everyday language."
      qa_pairs: "Generate approachable questions with easy-to-understand answers."
      summaries: "Create informal summaries using simple, conversational language."

    creative:
      conversations: "Create imaginative conversations using analogies, stories, and creative examples."
      qa_pairs: "Generate creative questions that encourage thinking outside the box."
      summaries: "Create engaging summaries with creative language and interesting perspectives."

    professional:
      conversations: "Create professional discussions with industry-specific terminology."
      qa_pairs: "Generate professional-level questions with expert insights."
      summaries: "Create business-focused summaries with actionable insights."
